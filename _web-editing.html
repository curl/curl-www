#include "_doctype.html"
<HTML>
<HEAD> <TITLE>curl - Web Site Editing Guidlines</TITLE>
#include "css.t"
</HEAD>

#include "_menu.html"
#include "setup.t"

TITLE(Web Site Editing Guidelines)
<p>
 <b>This document is intended for the curl web site editors only.</b>

<p>
 Check out the entire curl web site with:
<pre>
  git clone https://github.com/curl/curl-www.git
</pre>

<p>
  On the first checkout, run the bootstrap script:
<pre>
  sh bootstrap.sh
</pre>

<p>
  <a href="https://github.com/curl/curl-www">web site github repo</a>

SUBTITLE(To think of)
<p> The pages are preprocessed before they are finalized. The preprocessor
  is a simple C-style one, but please take care so that #if and #ifdefs
  have an ending #endif and so on.

<p> The web site contents is updated automatically from git every 20
  minutes. Even if you fix a mistake, it will stay that way at least until
  next update.  Don't panic!

<p> The site is hosted by CDN front-ends that fetch content from the master
  server and cache it. It makes some updates to the content to take a while
  until truly visible to end users.

SUBTITLE(What to edit/update)
<p> Add news items whenever you have interesting "news" you think the curl
  community might enjoy. The news section also serves a purpose of making it
  apparent that the site is living. Try to follow the tradition and style of
  previous news items. Note the use of the macros.

<p> The download page is maintained at <a href="/dl">dl</a> and needs
  special access rights.

<p> Edit bad language use, bad spelling or confusing use of words.

<p> If the problem is in a page out of control from the web site, chances
  are that the page is generated automatically from a file in the source code
  archive and then <i>that</i> file could be corrected instead.

SUBTITLE(Build prerequisites)
<p>
  The web site is a on old custom made setup that mostly builds static HTML
  files from a set of source files. The sources files are preprocessed with
  what is basically a souped-up C preprocessor
  called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a> and a set of
  perl scripts. The man pages get converted to HTML
  with <a href="https://daniel.haxx.se/projects/roffit/">roffit</a>. Make sure
  fcpp, perl, roffit, make and curl are all in your $PATH. Markdown files are
  converted
  by... <a href="http://daringfireball.net/projects/markdown/">markdown</a>
  (<tt>apt install markdown</tt>).

SUBTITLE(Build process)
<p>
  Once you've cloned the git repo the first time, invoke `sh bootstrap.sh` once
  to get a symlink and some some initial local files setup, and then you can
  build the web site locally by invoking make in the source root tree.
<p>
  Note that this doesn't make you a complete web site mirror, as some scripts
  and files are only available on the real actual site, but should give you
  enough to let you load most HTML pages locally.

SUBTITLE(Not in the git repo)
<p>
 Site content that is not mirrored and thus only available from <a
 href="//curl.haxx.se/">curl.haxx.se</a>:
<ul>
<li> <tt>/mail/</tt> Mailing list archives
<li> <tt>/download/</tt> Curl release archives/packages
<li> <tt>/latest.cgi</tt> script for display curl archive status on mirrors
</ul>

#include "_footer.html"
</BODY>
</HTML>
